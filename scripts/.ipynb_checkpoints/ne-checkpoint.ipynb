{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e6d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "body_cascade = cv2.CascadeClassifier('../haar/haarcascade_fullbody.xml')\n",
    "cap=cv2.VideoCapture('../videos/peopleWalking.mp4')\n",
    "while (1):\n",
    "    ret,img = cap.read()\n",
    "    img = cv2.flip(img,1)\n",
    "    gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    body = body_cascade.detectMultiScale(gray,1.3,5)\n",
    "    pts = []\n",
    "    p =[]\n",
    "    for(x,y,w,h) in body:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        cv2.circle(img,(int((2*x+w)/2),int((2*y+h)/2)),5,(255,0,0),5)\n",
    "        pts.append(int(2*x+w)/2)\n",
    "        p.append(int(2*y+h)/2)\n",
    "        for i in range(1, len(pts)):\n",
    "            if pts[i - 1] is None or pts[i] is None:\n",
    "                continue\n",
    "            cv2.line(img,(int(pts[i-1]),int(p[i-1])),(int(pts[i]),int(p[i])),(0,0,255),3)\n",
    "            a1=int(pts[i-1])\n",
    "            b1=int(p[i-1])\n",
    "            a2=int(pts[i])\n",
    "            b2=int(p[i])\n",
    "            c=math.sqrt((a1-a2)**2+(b1-b2)**2)\n",
    "            d=str(math.trunc(c/2))+\"inch\"\n",
    "            cv2.putText(img,d,(0,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3,cv2.LINE_AA)\n",
    "            if math.trunc(c/2)<20:\n",
    "                cv2.putText(img,\"WARNING\",(100,50),cv2.FONT_HERSHEY_SIMPLEX   ,1,(0,0,255),3,cv2.LINE_AA)\n",
    "                cv2.imshow('img',img)\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e26a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "### REFERENCES\n",
    "### https://www.pyimagesearch.com/2017/09/11/object-detection-with-deep-learning-and-opencv/\n",
    "### https://docs.opencv.org/4.3.0/d6/d0f/group__dnn.html\n",
    "### https://www.ebenezertechs.com/mobilenet-ssd-using-opencv-3-4-1-deep-learning-module-python/\n",
    "### https://www.pyimagesearch.com/2020/06/01/opencv-social-distancing-detector/\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from math import pow, sqrt\n",
    "\n",
    "#Constant Values\n",
    "preprocessing = False\n",
    "calculateConstant_x = 300\n",
    "calculateConstant_y = 615\n",
    "personLabelID = 15.00\n",
    "debug = True\n",
    "accuracyThreshold = 0.4\n",
    "RED = (0,0,255)\n",
    "YELLOW = (0,255,255)\n",
    "GREEN = (0,255,0)\n",
    "write_video = False\n",
    "\n",
    "# I used CLAHE preprocessing algorithm for detect humans better.\n",
    "# HSV (Hue, Saturation, and Value channel). CLAHE uses value channel.\n",
    "# Value channel refers to the lightness or darkness of a colour. An image without hue or saturation is a grayscale image.\n",
    "def CLAHE(bgr_image: np.array) -> np.array:\n",
    "    hsv = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2HSV)\n",
    "    hsv_planes = cv2.split(hsv)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    hsv_planes[2] = clahe.apply(hsv_planes[2])\n",
    "    hsv = cv2.merge(hsv_planes)\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "def centroid(startX,endX,startY,endY):\n",
    "    centroid_x = round((startX+endX)/2,4)\n",
    "    centroid_y = round((startY+endY)/2,4)\n",
    "    bboxHeight = round(endY-startY,4)\n",
    "    return centroid_x,centroid_y,bboxHeight\n",
    "\n",
    "def calcDistance(bboxHeight):\n",
    "    distance = (calculateConstant_x * calculateConstant_y) / bboxHeight\n",
    "    return distance\n",
    "\n",
    "def drawResult(frame,position):\n",
    "    for i in position.keys():\n",
    "        if i in highRisk:\n",
    "            rectangleColor = RED\n",
    "        elif i in mediumRisk:\n",
    "            rectangleColor = YELLOW\n",
    "        else:\n",
    "            rectangleColor = GREEN\n",
    "        (startX, startY, endX, endY) = detectionCoordinates[i]\n",
    "\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), rectangleColor, 2)\n",
    "\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "\n",
    "    caffeNetwork = cv2.dnn.readNetFromCaffe(\"./SSD_MobileNet_prototxt.txt\", \"./SSD_MobileNet.caffemodel\")\n",
    "    cap = cv2.VideoCapture(\"./pedestrians.mp4\")\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    output_movie = cv2.VideoWriter(\"./result.avi\", fourcc, 24, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "\n",
    "    while cap.isOpened():\n",
    "\n",
    "        debug_frame, frame = cap.read()\n",
    "        highRisk = set()\n",
    "        mediumRisk = set()\n",
    "        position = dict()\n",
    "        detectionCoordinates = dict()\n",
    "\n",
    "        if not debug_frame:\n",
    "            print(\"Video cannot opened or finished!\")\n",
    "            break\n",
    "\n",
    "        if preprocessing:\n",
    "            frame = CLAHE(frame)\n",
    "\n",
    "        (imageHeight, imageWidth) = frame.shape[:2]\n",
    "        pDetection = cv2.dnn.blobFromImage(cv2.resize(frame, (imageWidth, imageHeight)), 0.007843, (imageWidth, imageHeight), 127.5)\n",
    "\n",
    "        caffeNetwork.setInput(pDetection)\n",
    "        detections = caffeNetwork.forward()\n",
    "\n",
    "        for i in range(detections.shape[2]):\n",
    "\n",
    "            accuracy = detections[0, 0, i, 2]\n",
    "            if accuracy > accuracyThreshold:\n",
    "                # Detection class and detection box coordinates.\n",
    "                idOfClasses = int(detections[0, 0, i, 1])\n",
    "                box = detections[0, 0, i, 3:7] * np.array([imageWidth, imageHeight, imageWidth, imageHeight])\n",
    "                (startX, startY, endX, endY) = box.astype('int')\n",
    "\n",
    "                if idOfClasses == personLabelID:\n",
    "                    # Default drawing bounding box.\n",
    "                    bboxDefaultColor = (255,255,255)\n",
    "                    cv2.rectangle(frame, (startX, startY), (endX, endY), bboxDefaultColor, 2)\n",
    "                    detectionCoordinates[i] = (startX, startY, endX, endY)\n",
    "\n",
    "                    # Centroid of bounding boxes\n",
    "                    centroid_x, centroid_y, bboxHeight = centroid(startX,endX,startY,endY)                    \n",
    "                    distance = calcDistance(bboxHeight)\n",
    "                    # Centroid in centimeter distance\n",
    "                    centroid_x_centimeters = (centroid_x * distance) / calculateConstant_y\n",
    "                    centroid_y_centimeters = (centroid_y * distance) / calculateConstant_y\n",
    "                    position[i] = (centroid_x_centimeters, centroid_y_centimeters, distance)\n",
    "\n",
    "        #Risk Counter Using Distance of Positions\n",
    "        for i in position.keys():\n",
    "            for j in position.keys():\n",
    "                if i < j:\n",
    "                    distanceOfBboxes = sqrt(pow(position[i][0]-position[j][0],2) \n",
    "                                          + pow(position[i][1]-position[j][1],2) \n",
    "                                          + pow(position[i][2]-position[j][2],2)\n",
    "                                          )\n",
    "                    if distanceOfBboxes < 150: # 150cm or lower\n",
    "                        highRisk.add(i),highRisk.add(j)\n",
    "                    elif distanceOfBboxes < 200 > 150: # between 150 and 200\n",
    "                        mediumRisk.add(i),mediumRisk.add(j) \n",
    "       \n",
    "\n",
    "        cv2.putText(frame, \"Person in High Risk : \" + str(len(highRisk)) , (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"Person in Medium Risk : \" + str(len(mediumRisk)) , (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "        cv2.putText(frame, \"Detected Person : \" + str(len(detectionCoordinates)), (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        drawResult(frame, position)\n",
    "        if write_video:            \n",
    "            output_movie.write(frame)\n",
    "        cv2.imshow('Result', frame)\n",
    "        waitkey = cv2.waitKey(1)\n",
    "        if waitkey == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b169323b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
