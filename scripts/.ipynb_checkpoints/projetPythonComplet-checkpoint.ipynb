{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'object de notre travail consiste à implémenter un détecteur de distanciation sociale COVID-19 à l'aide d'OpenCV et des algorithmes de Machine learning (deep learning).\n",
    "ce programme permettant de détecter les objets (Personnes) et de vérifier \n",
    "si les persoonne sont proches les uns des autres ou nn.\n",
    "<li>s'ils sont distant du au moins du N pixels</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suite aux différents cours, TD et TP effectués durant notre semestre au sein de notre formation ABD, la lecture du video ne fut pas un grand problème  ainsi que le codage avec python. Cependant, grâce à différents documents retrouvés sur Internet, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous souhaitons concevoir par nos propres moyens, un programme de detectection distance sociale."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Les étapes que nous avons suivis sont les suivants:        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "<li >a - Lecture d’une vidéo contenant un certain nombre d’objets : personnes, véhicules </li>\n",
    "<li>Détection des objets : détecter seulement des personnes</li>\n",
    "<li> Calcul des distances entre chaque couple de personnes</li>\n",
    "<li> Vérifier, pour chaque couple de personnes, si la distance est inférieure à un seuil N\n",
    "donné</li>\n",
    "<li> Afficher le résultat</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('../videos/shoping.mp4')\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Please try another vidfeo !! if this error showed uop, know wether we are not supporting this type of video or this video occurs problems \")\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if ret == True:\n",
    "        cv2.imshow(\"People Walking\",frame)\n",
    "        key = cv2.waitKey(40)\n",
    "        if key==27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cv2.destroyAllWindows()         \n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('../videos/shoping.mp4')\n",
    "fullBody = cv2.CascadeClassifier('../haar/haarcascade_fullbody.xml')\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Please try another vidfeo !! if this error showed uop, know wether we are not supporting this type of video or this video occurs problems \")\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if ret == True:\n",
    "        bodies = fullBody.detectMultiScale(frame,1.8,1)\n",
    "        for(x,y,w,h) in bodies:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "        cv2.imshow(\"People Walking\",frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key==27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cv2.destroyAllWindows()         \n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def euclidienne(x1,y1,x2,y2):\n",
    "    absX = abs(x1-x2)\n",
    "    absY = abs(y1-y2)\n",
    "    dis = sqrt(absX**2) +sqrt(absY**2)\n",
    "    return dis\n",
    "euclidienne(6,10,2,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def center(x,y,x2,y2):\n",
    "    centerX= x+ round(((x2-x)/2))\n",
    "    centerY =y+ round((y2-y)/2)\n",
    "    return (centerX,centerY)\n",
    "center(6,2,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "affectedPeople = []\n",
    "notAffectedPeople = []\n",
    "nAp = set()\n",
    "Ap = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " donner le seuil à respecter : 122\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "cap = cv2.VideoCapture('../videos/shoping.mp4')\n",
    "fullBody = cv2.CascadeClassifier('../haar/haarcascade_fullbody.xml')\n",
    "seuil = float(input(' donner le seuil à respecter : '))\n",
    "idPeople = 0\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Please try another vidfeo !! if this error showed uop, know wether we are not supporting this type of video or this video occurs problems \")\n",
    "    \n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if ret == True:\n",
    "        bodies = fullBody.detectMultiScale(frame,1.3,1)\n",
    "        for(x,y,w,h) in bodies:\n",
    "            #idPeople +=1\n",
    "            dis=0\n",
    "            zonneAffec = False\n",
    "            for(x1,y1,w1,h1) in bodies:\n",
    "                if x!=x1 and y!=y1:\n",
    "                    X_Center,Y_Center = center(x,y,w,h)\n",
    "                    X1_Center,Y1_Center= center(x1,y1,w1,h1)\n",
    "                    #dis = math.sqrt(((x+w//2)-(x1+w1//2))**2+((y+h//2)-(y1+h//2))**2)\n",
    "                    dis = euclidienne(X_Center,Y_Center,X1_Center,Y1_Center)\n",
    "                    if dis<seuil:\n",
    "                        zonneAffec = True\n",
    "                        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "                if zonneAffec :\n",
    "                    cv2.circle(frame,(x+int(w/2),y+int(h/2)),3,(255,255,255),1)\n",
    "                    cv2.line(frame,(x+int(w/2),y+int(h/2)),(x1+int(w1/2),y1+int(h1/2)),(255,255,255),1)\n",
    "                    #cv2.putText(frame, 'Zone d affectation', (x+10, y+20),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                    #cv2.line(frame,(X_Center,Y_Center),(X1_Center,Y1_Center),(0,0,255),thickness=2)\n",
    "                else :\n",
    "                    cv2.circle(frame,(x+int(w/2),y+int(h/2)),3,(255,0,0),1)\n",
    "                    cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        cv2.imshow(\"People Walking\",frame)\n",
    "        if cv2.waitKey(25) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=\"3d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "affectedPeople_X = []\n",
    "affectedPeople_Y = []\n",
    "notAffectedPeople_X= []\n",
    "notAffectedPeople_Y = []\n",
    "a = []\n",
    "a = Ap\n",
    "\n",
    "print(len(Ap),len(nAp))\n",
    "\n",
    "\n",
    "for i in Ap:\n",
    "    affectedPeople_X.append(i[0])\n",
    "    affectedPeople_Y.append(i[1])\n",
    "import matplotlib.pyplot as plt \n",
    "plt.scatter(affectedPeople_X,affectedPeople_Y,color=\"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not Affected people :\n",
    "nAp = nAp - Ap\n",
    "\n",
    "for i in nAp:\n",
    "    notAffectedPeople_X.append(i[0])\n",
    "    notAffectedPeople_Y.append(i[1])\n",
    "plt.scatter(notAffectedPeople_X,notAffectedPeople_Y,color=\"g\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "cap = cv2.VideoCapture('../videos/shoping.mp4')\n",
    "fullBody = cv2.CascadeClassifier('../haar/haarcascade_fullbody.xml')\n",
    "seuil = float(input(' donner le seuil à respecter : '))\n",
    "idPeople = 0\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Please try another vidfeo !! if this error showed uop, know wether we are not supporting this type of video or this video occurs problems \")\n",
    "    \n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if ret == True:\n",
    "        bodies = fullBody.detectMultiScale(frame,1.3,1)\n",
    "        for(x,y,w,h) in bodies:\n",
    "            #idPeople +=1\n",
    "            dis=0\n",
    "            zonneAffec = False\n",
    "            for(x1,y1,w1,h1) in bodies:\n",
    "                if x!=x1 and y!=y1:\n",
    "                    X_Center,Y_Center = center(x,y,w,h)\n",
    "                    X1_Center,Y1_Center= center(x1,y1,w1,h1)\n",
    "                    #dis = math.sqrt(((x+w//2)-(x1+w1//2))**2+((y+h//2)-(y1+h//2))**2)\n",
    "                    dis = euclidienne(X_Center,Y_Center,X1_Center,Y1_Center)\n",
    "                    if dis<seuil:\n",
    "                        zonneAffec = True\n",
    "                        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "                if zonneAffec :\n",
    "                    cv2.circle(frame,(x+int(w/2),y+int(h/2)),3,(0,0,255),1)\n",
    "                    affectedPeople.append(center(x,y,w,h))\n",
    "                    Ap = set(affectedPeople)\n",
    "                    cv2.line(frame,(x+int(w/2),y+int(h/2)),(x1+int(w1/2),y1+int(h1/2)),(1,1,1),1)\n",
    "                    #cv2.putText(frame, 'Zone d affectation', (x+10, y+20),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                    #cv2.line(frame,(X_Center,Y_Center),(X1_Center,Y1_Center),(0,0,255),thickness=2)\n",
    "                else :\n",
    "                    cv2.circle(frame,(x+int(w/2),y+int(h/2)),3,(255,0,0),1)\n",
    "                    cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "                    notAffectedPeople.append(center(x,y,w,h))\n",
    "                    nAp = set(notAffectedPeople)\n",
    "        cv2.imshow(\"People Walking\",frame)\n",
    "        if cv2.waitKey(25) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
